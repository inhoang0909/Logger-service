import { redisClient } from "../config/database.js";
import Log from "../models/Log.js";

const LOG_QUEUE_KEY = process.env.LOG_QUEUE_KEY || "log_queue";
let buffer = [];
const BATCH_SIZE = 100;
const FLUSH_INTERVAL = 1000;

// Flush logs ra DB + update counter
const flushLogs = async () => {
  if (buffer.length === 0) return;
  const logsToInsert = buffer;
  buffer = [];

  try {
    console.log(`üì¶ Flushing ${logsToInsert.length} logs to MongoDB...`);
    await Log.insertMany(logsToInsert);

    const multi = redisClient.multi();
    for (const log of logsToInsert) {
      const counterKey = `log_counter:${log.date}`;
      const field = `${log.service}:${log.method}:${log.endpoint}:${log.status}:${log.ip}`;
      multi.hincrby(counterKey, field, 1);
    }
    await multi.exec();
    console.log(`‚úÖ Successfully inserted ${logsToInsert.length} logs`);
  } catch (err) {
    console.error("‚ùå Failed to flush logs:", err.message);
  }
};

// Flush ƒë·ªãnh k·ª≥
setInterval(flushLogs, FLUSH_INTERVAL);

// Heartbeat
setInterval(() => console.log(`‚ù§Ô∏è Worker alive, buffer size=${buffer.length}`), 10000);

export const startWorker = async () => {
  console.log("üöÄ Log worker started, waiting for logs...");

  const loop = async () => {
    try {
      const data = await redisClient.blpop(LOG_QUEUE_KEY, 0);
      console.log("üì• BLPOP raw data:", data);

      if (data && data[1]) {
        const logEntry = JSON.parse(data[1]);
        const logTime = logEntry.time || logEntry.timestamp || new Date().toISOString();

        buffer.push({
          service: logEntry.service || "unknown-service",
          endpoint: logEntry.endpoint || "unknown-endpoint",
          method: logEntry.method || "UNKNOWN",
          status: logEntry.status || 0,
          ip: logEntry.ip || "unknown-ip",
          duration: logEntry.durationMs || null,
          date: logTime.slice(0, 10),
          error: {
            message: logEntry.errorMessage || null,
            stack: logEntry.errorStack || null,
            payload: logEntry.payload || null,
          },
          createdAt: new Date(logTime),
        });

        console.log(`üì• Pulled log, buffer size=${buffer.length}`);
        if (buffer.length >= BATCH_SIZE) await flushLogs();
      }
    } catch (err) {
      console.error("‚ö†Ô∏è Worker error:", err.message);
    } finally {
      // g·ªçi l·∫°i ch√≠nh n√≥ ‚Üí tr√°nh block event loop
      setImmediate(loop);
    }
  };

  loop();
};

